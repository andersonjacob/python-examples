{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import concurrent.futures as futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.217307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.074995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.753345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.310279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.019605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.371197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.695124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.840065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.122004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.639414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a         b\n",
       "0  0 -0.217307\n",
       "1  1  0.074995\n",
       "2  2  0.753345\n",
       "3  3  0.310279\n",
       "4  4  0.019605\n",
       "5  5 -0.371197\n",
       "6  6 -1.695124\n",
       "7  7  0.840065\n",
       "8  8 -1.122004\n",
       "9  9 -0.639414"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 100\n",
    "df = pd.DataFrame({'a': np.arange(N), 'b': np.random.randn(N)})\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the apply function in pandas is a bad idea.  It will almost never give you competitive results\n",
    "\n",
    "Let's first define a simple function that adds to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ab(r):\n",
    "    return r.a + r.b\n",
    "\n",
    "def add_ab_i(r):\n",
    "    return r[1] + r[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"best\" way to do this is to just use the vectorization built into the underlying numpy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.3 µs ± 886 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df.a+df.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We could also use the mostly built in python functional programing constructs\n",
    "\n",
    "This is certainly slower than above, but what if you had a function that you couldn't break down into optimized, vectorized operations?\n",
    "\n",
    "This first one uses integer indexes and so you loose a little bit of the expressiveness, but we can regain that using the namedtuples from itertuples though we pay a price in speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453 µs ± 2.84 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.Series(list(map(add_ab_i, df.itertuples(name=None))), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916 µs ± 26.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.Series(list(map(add_ab, df.itertuples())), index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the apply method of a data frame we pay a significant speed penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42 ms ± 18.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df.apply(add_ab, axis=1, reduce=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a slightly more complicated function where we want to get a dataframe back out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sub_ab(r):\n",
    "    return {'apb': r.a+r.b, 'amb': r.a-r.b}\n",
    "\n",
    "def add_sub_ab_i(r):\n",
    "    return {'apb': r[1]+r[2], 'amb': r[1]-r[2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again using optimized vectorized operations is the fasted.  With the built-in python functional programming constructs doing well and using pandas apply running dismally behind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471 µs ± 15.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.02 ms ± 35.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.54 ms ± 60.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "25.4 ms ± 913 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.DataFrame({'apb': df.a + df.b, 'amb': df.a - df.b})\n",
    "%timeit pd.DataFrame(list(map(add_sub_ab_i, df.itertuples(name=None))), index=df.index)\n",
    "%timeit pd.DataFrame(list(map(add_sub_ab, df.itertuples())), index=df.index)\n",
    "%timeit df.apply(lambda r: pd.Series(add_sub_ab(r)), axis=1, reduce=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand now to four operations and four columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_op_ab(r):\n",
    "    return {'apb': r.a+r.b, 'amb': r.a-r.b,\n",
    "            'rtb': r.a*r.b, 'rdb': r.a/r.b}\n",
    "\n",
    "def four_op_ab_i(r):\n",
    "    return [r[1]+r[2], r[1]-r[2],\n",
    "            r[1]*r[2], r[1]/r[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the results hasn't changed, but it is interesting that the lead of the vectorized solution is shrinking.  This is of course because it is really running 4 loops through the data while the others are just one, but I don't think you'll ever beat the optimized solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656 µs ± 9.94 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.37 ms ± 15.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.91 ms ± 25.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "27.4 ms ± 259 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.DataFrame({'apb': df.a+df.b, 'amb': df.a-df.b, 'atb': df.a*df.b, 'adb': df.a/df.b})\n",
    "%timeit pd.DataFrame(list(map(four_op_ab_i, df.itertuples(name=None))), index=df.index, columns=['apb','amb','atb','adb'])\n",
    "%timeit pd.DataFrame(list(map(four_op_ab, df.itertuples())), index=df.index)\n",
    "%timeit df.apply(lambda r: pd.Series(four_op_ab(r)), reduce=False, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now define a parallel solution and a long running operation that you can't translate into vectorized operations.\n",
    "\n",
    "You'll see that the parallel apply is essentially the same pattern as the functional constructs that are built into python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_apply(df, func, **kwargs):\n",
    "    with futures.ProcessPoolExecutor(max_workers=kwargs.get('max_workers',None)) as executor:\n",
    "        rslt = list(executor.map(func, df.itertuples(name=None), chunksize=kwargs.get('chunksize', max(1,df.shape[0]//64))))\n",
    "    return pd.DataFrame(rslt, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def long_op_ab(r):\n",
    "    time.sleep(0.25)\n",
    "    return {'apb': r.a+r.b, 'amb': r.a-r.b,\n",
    "            'rtb': r.a*r.b, 'rdb': r.a/r.b}\n",
    "\n",
    "def long_op_ab_i(r):\n",
    "    time.sleep(0.25)\n",
    "    return [r[1]+r[2], r[1]-r[2],\n",
    "            r[1]*r[2], r[1]/r[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_big = int(1e3)\n",
    "df_big = pd.DataFrame({'a': np.arange(N_big), 'b': np.random.randn(N_big)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the pandas apply finishes as quickly as can be expected in a single threaded manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.52 s, sys: 24 ms, total: 1.55 s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%time df_big.apply(lambda r: pd.Series(long_op_ab(r)), reduce=False, axis=1)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the python function constructs is basically the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 188 ms, sys: 4 ms, total: 192 ms\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%time pd.DataFrame(list(map(long_op_ab_i, df_big.itertuples(name=None))), index=df_big.index)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use the parallel apply function then the time drops by almost the number of worker nodes.  It wasn't a very hard to implement, but it cannot use the namedtuples because of pickle problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 ms, sys: 52 ms, total: 108 ms\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%time parallel_apply(df_big, long_op_ab_i, chunksize=100, max_workers=4)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the only time you that pandas apply makes sense from a performance point of view is when you are running a computationally intense fucntion and you have to do it in a single thread.  Since even most low end computers have more than one processor there doesn't seem to be a general need to ever use apply.  You're better off using the vectorized operations when you can and when you cannot you are better off using a the regular functional contructs in python like map(...) or a parallel map(...) over the iterator of rows as tuples (not Series).  It doesn't require much code at all and can save huge amounts of time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
